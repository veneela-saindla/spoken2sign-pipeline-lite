{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers sentencepiece torch scikit-learn\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "print(\"✓ Drive mounted\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDapAOZG7uQc",
        "outputId": "fd9ee310-7a07-407e-d20e-2393d4c16c2b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "✓ Drive mounted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# CELL 2: Imports\n",
        "# ============================================\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.animation import FFMpegWriter\n",
        "import torch\n",
        "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
        "from IPython.display import Video, HTML\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"✓ All imports successful\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UZEnlwK7vpB",
        "outputId": "a6cb99cc-9461-4de9-819f-7ea79e350aee"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ All imports successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# CELL 3: Configuration\n",
        "# ============================================\n",
        "# YOUR PATHS\n",
        "PKL_PATH = \"/content/drive/MyDrive/phoenixsmall_unzipped/phoenixsmall/mediapipe_pose_keypoints.pkl\"\n",
        "GLOSS_CSV = \"/content/drive/MyDrive/phoenixsmall_unzipped/phoenixsmall/gloss_map.csv\"\n",
        "OUTPUT_DIR = \"/content/outputs\"\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Parameters\n",
        "FRAMES_PER_GLOSS = 48  # Standard duration for each sign\n",
        "FPS = 25\n",
        "VIDEO_WIDTH, VIDEO_HEIGHT = 960, 720\n",
        "\n",
        "# Verify paths\n",
        "print(\"Keypoints exist:\", os.path.exists(PKL_PATH))\n",
        "print(\"Gloss CSV exists:\", os.path.exists(GLOSS_CSV))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLvx_b-E76n4",
        "outputId": "4a9b972c-ce62-4845-870e-ee85ea16f729"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keypoints exist: True\n",
            "Gloss CSV exists: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# CELL 4: Load Data\n",
        "# ============================================\n",
        "print(\"\\n=== LOADING DATA ===\")\n",
        "\n",
        "# Load keypoints\n",
        "with open(PKL_PATH, \"rb\") as f:\n",
        "    kp_data = pickle.load(f)\n",
        "print(f\"✓ Loaded {len(kp_data)} videos\")\n",
        "\n",
        "# Load gloss mapping\n",
        "gloss_to_video = {}\n",
        "video_to_gloss = {}\n",
        "all_glosses = []\n",
        "\n",
        "with open(GLOSS_CSV, \"r\", encoding=\"utf-8\") as f:\n",
        "    reader = csv.reader(f)\n",
        "    header = next(reader)\n",
        "    video_idx = header.index(\"video\")\n",
        "    gloss_idx = header.index(\"gloss\")\n",
        "\n",
        "    for row in reader:\n",
        "        gloss = row[gloss_idx]\n",
        "        video = row[video_idx]\n",
        "        if video in kp_data:  # Only include videos we have keypoints for\n",
        "            gloss_to_video[gloss] = video\n",
        "            video_to_gloss[video] = gloss\n",
        "            all_glosses.append(gloss)\n",
        "\n",
        "unique_glosses = list(set(all_glosses))\n",
        "print(f\"✓ Loaded {len(gloss_to_video)} gloss-video pairs\")\n",
        "print(f\"✓ Unique glosses: {len(unique_glosses)}\")\n",
        "print(f\"Sample glosses: {unique_glosses[:10]}\")\n",
        "\n",
        "# Inspect data structure\n",
        "sample_video = list(kp_data.keys())[0]\n",
        "sample_frames = kp_data[sample_video]\n",
        "print(f\"\\nData structure check:\")\n",
        "print(f\"  Sample video: {sample_video}\")\n",
        "print(f\"  Number of frames: {len(sample_frames)}\")\n",
        "print(f\"  Keypoints per frame: {len(sample_frames[0])}\")\n",
        "print(f\"  First keypoint: {sample_frames[0][0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEXxF39N8XTi",
        "outputId": "8e1bf334-a4fb-466f-d5de-e15397015c32"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== LOADING DATA ===\n",
            "✓ Loaded 50 videos\n",
            "✓ Loaded 20 gloss-video pairs\n",
            "✓ Unique glosses: 20\n",
            "Sample glosses: ['GLOSS_10', 'GLOSS_18', 'GLOSS_2', 'GLOSS_16', 'GLOSS_9', 'GLOSS_8', 'GLOSS_11', 'GLOSS_13', 'GLOSS_1', 'GLOSS_5']\n",
            "\n",
            "Data structure check:\n",
            "  Sample video: 05October_2010_Tuesday_tagesschau-4236\n",
            "  Number of frames: 82\n",
            "  Keypoints per frame: 33\n",
            "  First keypoint: [0.483663409948349, 0.2328890562057495, -1.3068078756332397, 0.9956284761428833]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# CELL 5: Keypoint Processing Functions\n",
        "# ============================================\n",
        "def frames_to_np(frames):\n",
        "    \"\"\"Convert list of frames to numpy array\"\"\"\n",
        "    return np.array(frames, dtype=float)\n",
        "\n",
        "def resample_frames(frames_np, target_len):\n",
        "    \"\"\"Resample frames to target length using linear interpolation\"\"\"\n",
        "    n = frames_np.shape[0]\n",
        "    if n == target_len:\n",
        "        return frames_np\n",
        "\n",
        "    # Linear interpolation\n",
        "    idx = np.linspace(0, n-1, target_len)\n",
        "    low = np.floor(idx).astype(int)\n",
        "    high = np.ceil(idx).astype(int)\n",
        "    high = np.clip(high, 0, n-1)  # Ensure within bounds\n",
        "\n",
        "    w = (idx - low).reshape(-1, 1, 1)\n",
        "    return frames_np[low] * (1 - w) + frames_np[high] * w\n",
        "\n",
        "def smooth_sequence(seq, win_body=5, win_hands=12, hand_ids=(15, 16, 17, 18, 19, 20, 21, 22)):\n",
        "    \"\"\"Apply temporal smoothing to keypoint sequence\"\"\"\n",
        "    F, K, C = seq.shape\n",
        "    out = seq.copy()\n",
        "\n",
        "    for k in range(K):\n",
        "        win = win_hands if k in hand_ids else win_body\n",
        "        for i in range(F):\n",
        "            start = max(0, i - win // 2)\n",
        "            end = min(F, i + win // 2 + 1)\n",
        "            out[i, k] = seq[start:end, k].mean(axis=0)\n",
        "\n",
        "    return out\n",
        "\n",
        "def stabilize_pose(seq):\n",
        "    \"\"\"Stabilize the pose by centering around hip position\"\"\"\n",
        "    seq2 = seq.copy()\n",
        "\n",
        "    # MediaPipe hip keypoints are at indices 23 and 24\n",
        "    if seq2.shape[1] > 24:\n",
        "        hips = (seq2[:, 23, :2] + seq2[:, 24, :2]) / 2.0\n",
        "        hip_x, hip_y = np.median(hips[:, 0]), np.median(hips[:, 1])\n",
        "\n",
        "        # Center around (0.5, 0.6) for better framing\n",
        "        seq2[:, :, 0] -= (hip_x - 0.5)\n",
        "        seq2[:, :, 1] -= (hip_y - 0.6)\n",
        "\n",
        "    return seq2\n",
        "\n",
        "def fix_broken_frame(frame):\n",
        "    \"\"\"Repair invalid keypoints in a frame\"\"\"\n",
        "    fixed = []\n",
        "    for kp in frame:\n",
        "        try:\n",
        "            arr = np.array(kp, dtype=float)\n",
        "            if arr.size < 2:\n",
        "                arr = np.array([0., 0., 0., 0.], dtype=float)\n",
        "\n",
        "            # Ensure 4 values: [x, y, z, confidence]\n",
        "            if arr.size < 4:\n",
        "                arr = np.pad(arr, (0, 4 - arr.size), constant_values=0)\n",
        "            elif arr.size > 4:\n",
        "                arr = arr[:4]\n",
        "\n",
        "            if np.any(np.isnan(arr)) or np.any(np.isinf(arr)):\n",
        "                arr = np.array([0., 0., 0., 0.], dtype=float)\n",
        "        except:\n",
        "            arr = np.array([0., 0., 0., 0.], dtype=float)\n",
        "\n",
        "        fixed.append(arr)\n",
        "\n",
        "    return np.stack(fixed)\n",
        "\n",
        "print(\"✓ Keypoint processing functions ready\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yn74T5MH8ZU-",
        "outputId": "d364d3c6-cbc0-4f65-a271-130c283ad535"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Keypoint processing functions ready\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# CELL 6: Sign Connector (Co-articulation)\n",
        "# ============================================\n",
        "class SignConnector:\n",
        "    \"\"\"Predicts co-articulation duration and generates smooth transitions\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.default_duration = 8  # frames\n",
        "        self.hand_indices = [15, 16, 17, 18, 19, 20, 21, 22]  # MediaPipe hand keypoints\n",
        "\n",
        "    def predict_duration(self, sign1_end, sign2_start):\n",
        "        \"\"\"Predict co-articulation duration based on hand distance\"\"\"\n",
        "        # Extract hand positions\n",
        "        hands1 = sign1_end[self.hand_indices, :2]  # x, y only\n",
        "        hands2 = sign2_start[self.hand_indices, :2]\n",
        "\n",
        "        # Calculate Euclidean distance\n",
        "        distance = np.linalg.norm(hands1 - hands2)\n",
        "\n",
        "        # Scale duration based on distance (larger distance = longer transition)\n",
        "        duration = int(self.default_duration + distance * 20)\n",
        "        duration = np.clip(duration, 4, 20)  # Min 4, max 20 frames\n",
        "\n",
        "        return duration\n",
        "\n",
        "    def generate_coarticulation(self, sign1_end, sign2_start, duration):\n",
        "        \"\"\"Generate smooth transition between two signs\"\"\"\n",
        "        # Linear interpolation in 3D space\n",
        "        alphas = np.linspace(0, 1, duration).reshape(-1, 1, 1)\n",
        "        transition = sign1_end * (1 - alphas) + sign2_start * alphas\n",
        "\n",
        "        return transition\n",
        "\n",
        "connector = SignConnector()\n",
        "print(\"✓ Sign connector initialized\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEAtejsN8gha",
        "outputId": "44e451d9-0644-49ad-e4ad-9a9c2c03a608"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Sign connector initialized\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# CELL 7: Sign Sequence Builder\n",
        "# ============================================\n",
        "def get_sequence_for_gloss(gloss):\n",
        "    \"\"\"Get keypoint sequence for a single gloss\"\"\"\n",
        "    if gloss not in gloss_to_video:\n",
        "        print(f\"Warning: Gloss '{gloss}' not found, using random sign\")\n",
        "        gloss = np.random.choice(list(gloss_to_video.keys()))\n",
        "\n",
        "    video_id = gloss_to_video[gloss]\n",
        "    frames_list = kp_data[video_id]\n",
        "\n",
        "    # Convert to numpy and resample\n",
        "    arr = frames_to_np(frames_list)\n",
        "    resampled = resample_frames(arr, FRAMES_PER_GLOSS)\n",
        "\n",
        "    return resampled\n",
        "\n",
        "def build_sequence(gloss_list):\n",
        "    \"\"\"Build complete sign sequence from gloss list with co-articulations\"\"\"\n",
        "    if not gloss_list:\n",
        "        raise ValueError(\"Gloss list cannot be empty\")\n",
        "\n",
        "    # Get all sign sequences\n",
        "    sign_sequences = [get_sequence_for_gloss(g) for g in gloss_list]\n",
        "\n",
        "    # Build final sequence with co-articulations\n",
        "    final_sequence = [sign_sequences[0]]\n",
        "\n",
        "    for i in range(1, len(sign_sequences)):\n",
        "        prev_sign_end = sign_sequences[i-1][-1]\n",
        "        curr_sign_start = sign_sequences[i][0]\n",
        "\n",
        "        # Predict and generate co-articulation\n",
        "        duration = connector.predict_duration(prev_sign_end, curr_sign_start)\n",
        "        coartic = connector.generate_coarticulation(\n",
        "            prev_sign_end, curr_sign_start, duration\n",
        "        )\n",
        "\n",
        "        final_sequence.append(coartic)\n",
        "        final_sequence.append(sign_sequences[i])\n",
        "\n",
        "    # Concatenate all parts\n",
        "    full_seq = np.concatenate(final_sequence, axis=0)\n",
        "\n",
        "    # Apply smoothing and stabilization\n",
        "    full_seq = smooth_sequence(full_seq)\n",
        "    full_seq = stabilize_pose(full_seq)\n",
        "\n",
        "    return full_seq\n",
        "\n",
        "print(\"✓ Sequence builder ready\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGyzhNRa8lC_",
        "outputId": "97a76cf9-9a18-4ccb-e2b8-4663dd82834c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Sequence builder ready\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# CELL 8: Video Renderer\n",
        "# ============================================\n",
        "# MediaPipe pose connections (skeleton)\n",
        "POSE_CONNECTIONS = [\n",
        "    # Face\n",
        "    (0, 1), (1, 2), (2, 3), (3, 7),\n",
        "    (0, 4), (4, 5), (5, 6), (6, 8),\n",
        "    # Torso\n",
        "    (9, 10),\n",
        "    (11, 12), (11, 13), (13, 15),  # Left arm\n",
        "    (12, 14), (14, 16),  # Right arm\n",
        "    (11, 23), (12, 24),  # Torso to hips\n",
        "    (23, 24),  # Hips\n",
        "    # Legs\n",
        "    (23, 25), (25, 27), (27, 29), (29, 31),  # Left leg\n",
        "    (24, 26), (26, 28), (28, 30), (30, 32),  # Right leg\n",
        "    # Hands\n",
        "    (15, 17), (15, 19), (15, 21),  # Left hand\n",
        "    (16, 18), (16, 20), (16, 22),  # Right hand\n",
        "]\n",
        "\n",
        "def frame_to_pixels(frame, width=VIDEO_WIDTH, height=VIDEO_HEIGHT):\n",
        "    \"\"\"Convert normalized coordinates to pixel coordinates\"\"\"\n",
        "    arr = np.array(frame, dtype=float)\n",
        "    if arr.shape[1] < 2:\n",
        "        return np.zeros((arr.shape[0], 2))\n",
        "\n",
        "    x = np.clip(arr[:, 0], 0, 1) * width\n",
        "    y = np.clip(arr[:, 1], 0, 1) * height\n",
        "\n",
        "    pts = np.stack([x, y], axis=1)\n",
        "    pts[~np.isfinite(pts)] = 0\n",
        "\n",
        "    return pts\n",
        "\n",
        "def render_video(sequence, output_path, title=\"Sign Language\"):\n",
        "    \"\"\"Render keypoint sequence as video\"\"\"\n",
        "    print(f\"\\n=== RENDERING VIDEO ===\")\n",
        "    print(f\"Frames: {len(sequence)}\")\n",
        "    print(f\"Output: {output_path}\")\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(VIDEO_WIDTH/100, VIDEO_HEIGHT/100), dpi=100)\n",
        "    ax.set_xlim(0, VIDEO_WIDTH)\n",
        "    ax.set_ylim(VIDEO_HEIGHT, 0)\n",
        "    ax.axis('off')\n",
        "    ax.set_facecolor('#f0f0f0')\n",
        "\n",
        "    # Initialize plot elements\n",
        "    scatter = ax.scatter([], [], s=80, c='#2c3e50', zorder=3, alpha=0.8)\n",
        "    lines = [ax.plot([], [], linewidth=6, color='#34495e',\n",
        "                     solid_capstyle='round', alpha=0.7)[0]\n",
        "             for _ in POSE_CONNECTIONS]\n",
        "\n",
        "    # Highlight hands\n",
        "    left_hand = ax.plot([], [], 'o', markersize=20, color='#e74c3c',\n",
        "                        markeredgecolor='white', markeredgewidth=2, zorder=5)[0]\n",
        "    right_hand = ax.plot([], [], 'o', markersize=20, color='#3498db',\n",
        "                         markeredgecolor='white', markeredgewidth=2, zorder=5)[0]\n",
        "\n",
        "    # Add title\n",
        "    ax.text(VIDEO_WIDTH/2, 50, title, fontsize=24, ha='center',\n",
        "            weight='bold', color='#2c3e50')\n",
        "\n",
        "    writer = FFMpegWriter(fps=FPS, bitrate=5000)\n",
        "\n",
        "    with writer.saving(fig, output_path, 100):\n",
        "        for i, frame in enumerate(sequence):\n",
        "            if i % 25 == 0:\n",
        "                print(f\"  Progress: {i}/{len(sequence)} frames\", end='\\r')\n",
        "\n",
        "            # Fix frame and convert to pixels\n",
        "            frame_fixed = fix_broken_frame(frame)\n",
        "            pts = frame_to_pixels(frame_fixed)\n",
        "\n",
        "            # Update keypoints\n",
        "            scatter.set_offsets(pts)\n",
        "\n",
        "            # Update skeleton lines\n",
        "            for line, (a, b) in zip(lines, POSE_CONNECTIONS):\n",
        "                if a < len(pts) and b < len(pts):\n",
        "                    xa, ya = float(pts[a, 0]), float(pts[a, 1])\n",
        "                    xb, yb = float(pts[b, 0]), float(pts[b, 1])\n",
        "\n",
        "                    # Only draw if both points are valid\n",
        "                    if xa > 0 and ya > 0 and xb > 0 and yb > 0:\n",
        "                        line.set_data([xa, xb], [ya, yb])\n",
        "                    else:\n",
        "                        line.set_data([], [])\n",
        "                else:\n",
        "                    line.set_data([], [])\n",
        "\n",
        "            # Update hand markers (wrists: 15=left, 16=right)\n",
        "            if 15 < len(pts) and pts[15, 0] > 0:\n",
        "                left_hand.set_data([pts[15, 0]], [pts[15, 1]])\n",
        "            else:\n",
        "                left_hand.set_data([], [])\n",
        "\n",
        "            if 16 < len(pts) and pts[16, 0] > 0:\n",
        "                right_hand.set_data([pts[16, 0]], [pts[16, 1]])\n",
        "            else:\n",
        "                right_hand.set_data([], [])\n",
        "\n",
        "            writer.grab_frame()\n",
        "\n",
        "    plt.close(fig)\n",
        "    print(f\"\\n✓ Video saved: {output_path}\")\n",
        "\n",
        "print(\"✓ Renderer ready\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y88jqrrL8qp1",
        "outputId": "894bf2bc-dd65-4a28-ca66-ed46c805cddb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Renderer ready\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# CELL 9: Text-to-Gloss Translator (Simple Version)\n",
        "# ============================================\n",
        "class SimpleText2Gloss:\n",
        "    \"\"\"Simple rule-based text-to-gloss translator\"\"\"\n",
        "\n",
        "    def __init__(self, glosses):\n",
        "        self.glosses = glosses\n",
        "        self.gloss_set = set(glosses)\n",
        "\n",
        "    def translate(self, text):\n",
        "        \"\"\"\n",
        "        Simple translation: map words to glosses\n",
        "        In production, this would be an mBART model\n",
        "        \"\"\"\n",
        "        words = text.upper().replace('.', '').replace(',', '').split()\n",
        "        gloss_sequence = []\n",
        "\n",
        "        for word in words:\n",
        "            # Try direct match\n",
        "            if word in self.gloss_set:\n",
        "                gloss_sequence.append(word)\n",
        "            # Try with GLOSS_ prefix (common pattern)\n",
        "            elif f\"GLOSS_{word}\" in self.gloss_set:\n",
        "                gloss_sequence.append(f\"GLOSS_{word}\")\n",
        "            # Try fuzzy match (find similar gloss)\n",
        "            else:\n",
        "                for gloss in self.glosses:\n",
        "                    if word in gloss or gloss in word:\n",
        "                        gloss_sequence.append(gloss)\n",
        "                        break\n",
        "\n",
        "        # If no matches found, use random glosses\n",
        "        if not gloss_sequence:\n",
        "            gloss_sequence = [np.random.choice(self.glosses)\n",
        "                             for _ in range(min(len(words), 5))]\n",
        "\n",
        "        return gloss_sequence\n",
        "\n",
        "translator = SimpleText2Gloss(unique_glosses)\n",
        "print(\"✓ Text2Gloss translator ready\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4VOFwP48w9f",
        "outputId": "caead62b-d93c-4fe8-fed2-036e3746a3d5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Text2Gloss translator ready\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# CELL 10: Complete Pipeline Function\n",
        "# ============================================\n",
        "def spoken_to_sign(text, output_name=\"output\"):\n",
        "    \"\"\"Complete Spoken2Sign pipeline\"\"\"\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"SPOKEN2SIGN TRANSLATION\")\n",
        "    print(f\"{'='*50}\")\n",
        "    print(f\"Input text: {text}\")\n",
        "\n",
        "    # Step 1: Text to Gloss\n",
        "    print(\"\\n[1/3] Translating text to gloss sequence...\")\n",
        "    gloss_sequence = translator.translate(text)\n",
        "    print(f\"  Gloss sequence: {gloss_sequence}\")\n",
        "\n",
        "    # Step 2: Build sign sequence\n",
        "    print(\"\\n[2/3] Building sign sequence...\")\n",
        "    sign_sequence = build_sequence(gloss_sequence)\n",
        "    print(f\"  Total frames: {len(sign_sequence)}\")\n",
        "    print(f\"  Duration: {len(sign_sequence) / FPS:.2f} seconds\")\n",
        "\n",
        "    # Step 3: Render video\n",
        "    print(\"\\n[3/3] Rendering video...\")\n",
        "    output_path = f\"{OUTPUT_DIR}/{output_name}.mp4\"\n",
        "    render_video(sign_sequence, output_path, title=text[:40])\n",
        "\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"✓ TRANSLATION COMPLETE!\")\n",
        "    print(f\"{'='*50}\")\n",
        "\n",
        "    return output_path, gloss_sequence\n",
        "\n",
        "print(\"✓ Complete pipeline ready\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxksOmqJ822D",
        "outputId": "c740668d-57b0-48db-cda5-91f9d8039886"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Complete pipeline ready\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# CELL 11: TEST THE SYSTEM\n",
        "# ============================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TESTING SPOKEN2SIGN SYSTEM\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Test with first 3 glosses\n",
        "test_glosses = unique_glosses[:3]\n",
        "print(f\"\\nTest 1: Using glosses directly\")\n",
        "print(f\"Glosses: {test_glosses}\")\n",
        "\n",
        "sequence = build_sequence(test_glosses)\n",
        "output1 = f\"{OUTPUT_DIR}/test_direct_glosses.mp4\"\n",
        "render_video(sequence, output1, title=\"Test: Direct Glosses\")\n",
        "\n",
        "# Display video\n",
        "display(Video(output1, width=640, height=480))\n"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/content/outputs/test_direct_glosses.mp4": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "1449"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "status": 404,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "id": "3pDJAVnR86-I",
        "outputId": "1e51c958-2976-46d7-d46d-ccf4a290f57c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "TESTING SPOKEN2SIGN SYSTEM\n",
            "============================================================\n",
            "\n",
            "Test 1: Using glosses directly\n",
            "Glosses: ['GLOSS_10', 'GLOSS_18', 'GLOSS_2']\n",
            "\n",
            "=== RENDERING VIDEO ===\n",
            "Frames: 181\n",
            "Output: /content/outputs/test_direct_glosses.mp4\n",
            "\n",
            "✓ Video saved: /content/outputs/test_direct_glosses.mp4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Video object>"
            ],
            "text/html": [
              "<video src=\"/content/outputs/test_direct_glosses.mp4\" controls  width=\"640\"  height=\"480\">\n",
              "      Your browser does not support the <code>video</code> element.\n",
              "    </video>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# CELL 12: TEXT-TO-SIGN TRANSLATION\n",
        "# ============================================\n",
        "# Now test with actual text\n",
        "test_texts = [\n",
        "    \"HELLO WORLD\",\n",
        "    \"GOOD MORNING\",\n",
        "    \"THANK YOU\"\n",
        "]\n",
        "\n",
        "for i, text in enumerate(test_texts):\n",
        "    video_path, glosses = spoken_to_sign(text, f\"translation_{i+1}\")\n",
        "    print(f\"\\nVideo saved: {video_path}\")\n",
        "    print(f\"Glosses used: {glosses}\\n\")\n",
        "    display(Video(video_path, width=640, height=480))"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/content/outputs/translation_1.mp4": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "1449"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "status": 404,
              "status_text": ""
            },
            "http://localhost:8080/content/outputs/translation_2.mp4": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "1449"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "status": 404,
              "status_text": ""
            },
            "http://localhost:8080/content/outputs/translation_3.mp4": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "1449"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "status": 404,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QDFCGqcZ9UKF",
        "outputId": "f541a8ed-0396-4a86-9583-63a1d56e87ba"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "SPOKEN2SIGN TRANSLATION\n",
            "==================================================\n",
            "Input text: HELLO WORLD\n",
            "\n",
            "[1/3] Translating text to gloss sequence...\n",
            "  Gloss sequence: [np.str_('GLOSS_6'), np.str_('GLOSS_8')]\n",
            "\n",
            "[2/3] Building sign sequence...\n",
            "  Total frames: 107\n",
            "  Duration: 4.28 seconds\n",
            "\n",
            "[3/3] Rendering video...\n",
            "\n",
            "=== RENDERING VIDEO ===\n",
            "Frames: 107\n",
            "Output: /content/outputs/translation_1.mp4\n",
            "\n",
            "✓ Video saved: /content/outputs/translation_1.mp4\n",
            "\n",
            "==================================================\n",
            "✓ TRANSLATION COMPLETE!\n",
            "==================================================\n",
            "\n",
            "Video saved: /content/outputs/translation_1.mp4\n",
            "Glosses used: [np.str_('GLOSS_6'), np.str_('GLOSS_8')]\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Video object>"
            ],
            "text/html": [
              "<video src=\"/content/outputs/translation_1.mp4\" controls  width=\"640\"  height=\"480\">\n",
              "      Your browser does not support the <code>video</code> element.\n",
              "    </video>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "SPOKEN2SIGN TRANSLATION\n",
            "==================================================\n",
            "Input text: GOOD MORNING\n",
            "\n",
            "[1/3] Translating text to gloss sequence...\n",
            "  Gloss sequence: [np.str_('GLOSS_8'), np.str_('GLOSS_16')]\n",
            "\n",
            "[2/3] Building sign sequence...\n",
            "  Total frames: 112\n",
            "  Duration: 4.48 seconds\n",
            "\n",
            "[3/3] Rendering video...\n",
            "\n",
            "=== RENDERING VIDEO ===\n",
            "Frames: 112\n",
            "Output: /content/outputs/translation_2.mp4\n",
            "\n",
            "✓ Video saved: /content/outputs/translation_2.mp4\n",
            "\n",
            "==================================================\n",
            "✓ TRANSLATION COMPLETE!\n",
            "==================================================\n",
            "\n",
            "Video saved: /content/outputs/translation_2.mp4\n",
            "Glosses used: [np.str_('GLOSS_8'), np.str_('GLOSS_16')]\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Video object>"
            ],
            "text/html": [
              "<video src=\"/content/outputs/translation_2.mp4\" controls  width=\"640\"  height=\"480\">\n",
              "      Your browser does not support the <code>video</code> element.\n",
              "    </video>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "SPOKEN2SIGN TRANSLATION\n",
            "==================================================\n",
            "Input text: THANK YOU\n",
            "\n",
            "[1/3] Translating text to gloss sequence...\n",
            "  Gloss sequence: [np.str_('GLOSS_17'), np.str_('GLOSS_5')]\n",
            "\n",
            "[2/3] Building sign sequence...\n",
            "  Total frames: 116\n",
            "  Duration: 4.64 seconds\n",
            "\n",
            "[3/3] Rendering video...\n",
            "\n",
            "=== RENDERING VIDEO ===\n",
            "Frames: 116\n",
            "Output: /content/outputs/translation_3.mp4\n",
            "\n",
            "✓ Video saved: /content/outputs/translation_3.mp4\n",
            "\n",
            "==================================================\n",
            "✓ TRANSLATION COMPLETE!\n",
            "==================================================\n",
            "\n",
            "Video saved: /content/outputs/translation_3.mp4\n",
            "Glosses used: [np.str_('GLOSS_17'), np.str_('GLOSS_5')]\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Video object>"
            ],
            "text/html": [
              "<video src=\"/content/outputs/translation_3.mp4\" controls  width=\"640\"  height=\"480\">\n",
              "      Your browser does not support the <code>video</code> element.\n",
              "    </video>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# CELL 13: INTERACTIVE TRANSLATION\n",
        "# ============================================\n",
        "def translate_custom_text():\n",
        "    \"\"\"Interactive function for custom translations\"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"CUSTOM TEXT TRANSLATION\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"\\nAvailable glosses sample:\", unique_glosses[:20])\n",
        "    print(f\"\\nTotal glosses available: {len(unique_glosses)}\")\n",
        "\n",
        "    # Get user input\n",
        "    text = input(\"\\nEnter text to translate to sign language: \")\n",
        "\n",
        "    if text:\n",
        "        video_path, glosses = spoken_to_sign(text, \"custom_translation\")\n",
        "        display(Video(video_path, width=640, height=480))\n",
        "        return video_path\n",
        "    else:\n",
        "        print(\"No text entered\")\n",
        "\n",
        "# Run interactive translation\n",
        "translate_custom_text()\n"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/content/outputs/custom_translation.mp4": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "1449"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "status": 404,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xNkwrUl39bmp",
        "outputId": "4f929ccd-b0e0-4450-d9f6-7be95a6ce345"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "CUSTOM TEXT TRANSLATION\n",
            "============================================================\n",
            "\n",
            "Available glosses sample: ['GLOSS_10', 'GLOSS_18', 'GLOSS_2', 'GLOSS_16', 'GLOSS_9', 'GLOSS_8', 'GLOSS_11', 'GLOSS_13', 'GLOSS_1', 'GLOSS_5', 'GLOSS_3', 'GLOSS_12', 'GLOSS_0', 'GLOSS_19', 'GLOSS_15', 'GLOSS_17', 'GLOSS_6', 'GLOSS_4', 'GLOSS_7', 'GLOSS_14']\n",
            "\n",
            "Total glosses available: 20\n",
            "\n",
            "Enter text to translate to sign language: I go school\n",
            "\n",
            "==================================================\n",
            "SPOKEN2SIGN TRANSLATION\n",
            "==================================================\n",
            "Input text: I go school\n",
            "\n",
            "[1/3] Translating text to gloss sequence...\n",
            "  Gloss sequence: [np.str_('GLOSS_17'), np.str_('GLOSS_13'), np.str_('GLOSS_6')]\n",
            "\n",
            "[2/3] Building sign sequence...\n",
            "  Total frames: 178\n",
            "  Duration: 7.12 seconds\n",
            "\n",
            "[3/3] Rendering video...\n",
            "\n",
            "=== RENDERING VIDEO ===\n",
            "Frames: 178\n",
            "Output: /content/outputs/custom_translation.mp4\n",
            "\n",
            "✓ Video saved: /content/outputs/custom_translation.mp4\n",
            "\n",
            "==================================================\n",
            "✓ TRANSLATION COMPLETE!\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Video object>"
            ],
            "text/html": [
              "<video src=\"/content/outputs/custom_translation.mp4\" controls  width=\"640\"  height=\"480\">\n",
              "      Your browser does not support the <code>video</code> element.\n",
              "    </video>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/outputs/custom_translation.mp4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# CELL 14: BATCH PROCESSING\n",
        "# ============================================\n",
        "def batch_translate(text_list, output_prefix=\"batch\"):\n",
        "    \"\"\"Translate multiple texts\"\"\"\n",
        "    results = []\n",
        "\n",
        "    for i, text in enumerate(text_list):\n",
        "        print(f\"\\n{'='*50}\")\n",
        "        print(f\"Processing {i+1}/{len(text_list)}: {text}\")\n",
        "        print(f\"{'='*50}\")\n",
        "\n",
        "        video_path, glosses = spoken_to_sign(text, f\"{output_prefix}_{i+1}\")\n",
        "        results.append({\n",
        "            'text': text,\n",
        "            'glosses': glosses,\n",
        "            'video': video_path\n",
        "        })\n",
        "\n",
        "    return results\n",
        "\n",
        "# Example batch processing\n",
        "batch_texts = [\n",
        "    \"HELLO\",\n",
        "    \"GOODBYE\",\n",
        "    \"THANK YOU\"\n",
        "]\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"BATCH TRANSLATION DEMO\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "batch_results = batch_translate(batch_texts[:2], \"demo\")  # Process first 2\n",
        "\n",
        "# Display all results\n",
        "for result in batch_results:\n",
        "    print(f\"\\nText: {result['text']}\")\n",
        "    print(f\"Glosses: {result['glosses']}\")\n",
        "    display(Video(result['video'], width=640, height=480))\n"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/content/outputs/demo_1.mp4": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "1449"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "status": 404,
              "status_text": ""
            },
            "http://localhost:8080/content/outputs/demo_2.mp4": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "1449"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "status": 404,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3rCi-p7994xn",
        "outputId": "cbbafc14-1a8b-4bcc-81e8-ffc5a41b76e9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "BATCH TRANSLATION DEMO\n",
            "============================================================\n",
            "\n",
            "==================================================\n",
            "Processing 1/2: HELLO\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "SPOKEN2SIGN TRANSLATION\n",
            "==================================================\n",
            "Input text: HELLO\n",
            "\n",
            "[1/3] Translating text to gloss sequence...\n",
            "  Gloss sequence: [np.str_('GLOSS_1')]\n",
            "\n",
            "[2/3] Building sign sequence...\n",
            "  Total frames: 48\n",
            "  Duration: 1.92 seconds\n",
            "\n",
            "[3/3] Rendering video...\n",
            "\n",
            "=== RENDERING VIDEO ===\n",
            "Frames: 48\n",
            "Output: /content/outputs/demo_1.mp4\n",
            "\n",
            "✓ Video saved: /content/outputs/demo_1.mp4\n",
            "\n",
            "==================================================\n",
            "✓ TRANSLATION COMPLETE!\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "Processing 2/2: GOODBYE\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "SPOKEN2SIGN TRANSLATION\n",
            "==================================================\n",
            "Input text: GOODBYE\n",
            "\n",
            "[1/3] Translating text to gloss sequence...\n",
            "  Gloss sequence: [np.str_('GLOSS_5')]\n",
            "\n",
            "[2/3] Building sign sequence...\n",
            "  Total frames: 48\n",
            "  Duration: 1.92 seconds\n",
            "\n",
            "[3/3] Rendering video...\n",
            "\n",
            "=== RENDERING VIDEO ===\n",
            "Frames: 48\n",
            "Output: /content/outputs/demo_2.mp4\n",
            "\n",
            "✓ Video saved: /content/outputs/demo_2.mp4\n",
            "\n",
            "==================================================\n",
            "✓ TRANSLATION COMPLETE!\n",
            "==================================================\n",
            "\n",
            "Text: HELLO\n",
            "Glosses: [np.str_('GLOSS_1')]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Video object>"
            ],
            "text/html": [
              "<video src=\"/content/outputs/demo_1.mp4\" controls  width=\"640\"  height=\"480\">\n",
              "      Your browser does not support the <code>video</code> element.\n",
              "    </video>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Text: GOODBYE\n",
            "Glosses: [np.str_('GLOSS_5')]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Video object>"
            ],
            "text/html": [
              "<video src=\"/content/outputs/demo_2.mp4\" controls  width=\"640\"  height=\"480\">\n",
              "      Your browser does not support the <code>video</code> element.\n",
              "    </video>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# CELL 15: SYSTEM STATISTICS\n",
        "# ============================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SYSTEM STATISTICS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\nDataset:\")\n",
        "print(f\"  Total videos: {len(kp_data)}\")\n",
        "print(f\"  Total glosses: {len(unique_glosses)}\")\n",
        "print(f\"  Gloss-video pairs: {len(gloss_to_video)}\")\n",
        "\n",
        "print(f\"\\nConfiguration:\")\n",
        "print(f\"  Frames per gloss: {FRAMES_PER_GLOSS}\")\n",
        "print(f\"  Video FPS: {FPS}\")\n",
        "print(f\"  Resolution: {VIDEO_WIDTH}x{VIDEO_HEIGHT}\")\n",
        "\n",
        "print(f\"\\nOutput directory: {OUTPUT_DIR}\")\n",
        "print(f\"  Files created: {len(os.listdir(OUTPUT_DIR))}\")\n",
        "\n",
        "# List all output files\n",
        "print(f\"\\nGenerated videos:\")\n",
        "for file in sorted(os.listdir(OUTPUT_DIR)):\n",
        "    if file.endswith('.mp4'):\n",
        "        file_path = os.path.join(OUTPUT_DIR, file)\n",
        "        size_mb = os.path.getsize(file_path) / (1024*1024)\n",
        "        print(f\"  - {file} ({size_mb:.2f} MB)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"✓ SYSTEM READY FOR USE!\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSR7C3if-D3A",
        "outputId": "f6d5ef26-868e-412b-ddf2-3f5fea61c254"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "SYSTEM STATISTICS\n",
            "============================================================\n",
            "\n",
            "Dataset:\n",
            "  Total videos: 50\n",
            "  Total glosses: 20\n",
            "  Gloss-video pairs: 20\n",
            "\n",
            "Configuration:\n",
            "  Frames per gloss: 48\n",
            "  Video FPS: 25\n",
            "  Resolution: 960x720\n",
            "\n",
            "Output directory: /content/outputs\n",
            "  Files created: 7\n",
            "\n",
            "Generated videos:\n",
            "  - custom_translation.mp4 (1.96 MB)\n",
            "  - demo_1.mp4 (0.44 MB)\n",
            "  - demo_2.mp4 (0.39 MB)\n",
            "  - test_direct_glosses.mp4 (1.77 MB)\n",
            "  - translation_1.mp4 (1.16 MB)\n",
            "  - translation_2.mp4 (1.10 MB)\n",
            "  - translation_3.mp4 (1.13 MB)\n",
            "\n",
            "============================================================\n",
            "✓ SYSTEM READY FOR USE!\n",
            "============================================================\n"
          ]
        }
      ]
    }
  ]
}